{
    "collab_server" : "",
    "contents" : "# get CSR rating for unit page\n#' get CSR rating from a website for a unit page\n#' @param page on Which page you want to scrap\n#' @param proxy whether use the proxy, default is FALSE\n#' @param date represents the date is until which date, usually it's the last day of a year\n#' e.g., \"2015-12-31\" for the date of year 2015, \"2014-12-31\" for the date of year 2014\n#' @details\n#' Get CSR ratings and reports of different companies from http://stockdata.stock.hexun.com/zrbg/\n#' @return A table of CSR ratings collected from your input page\n#' @importFrom V8 v8\n#' @importFrom rvest html_table %>%\n#' @importFrom httr content use_proxy\n#' @importFrom stringi stri_replace_last_fixed stri_replace_first_fixed\n#' @importFrom jsonlite fromJSON\n#' @export\ngetCSRRating_unit <- function(page, date, proxy = NULL) {\n  engine <- v8()\n  url <- 'http://stockdata.stock.hexun.com/zrbg/data/zrbList.aspx?'\n\n  res <- GET(url, query = list(date = date,\n                               count = 20,\n                               pname = 20,\n                               titType = 'null',\n                               page = page), use_proxy(proxy[1, 1], proxy[1, 2]), timeout(15))\n\n  resC <- content(res) %>%\n    stri_replace_first_fixed(\"hxbase_json1(\", \"var dat=\") %>%\n    stri_replace_last_fixed(\")\", \"\") %>%\n    engine$eval()\n\n\n  resC <- engine$get('dat')$list\n  return(resC)\n}\n\n\n\n\n\n# get CSR rating\n#' get CSR rating from a website\n#' @param startPage on Which page you want to start, default is 1\n#' @param endPage On which page you want to stop scrapping\n#' @param year In which year you want the rank\n#' @param proxy whether use the proxy, default is FALSE\n#' @details\n#' Get CSR ratings and reports of different companies from http://stockdata.stock.hexun.com/zrbg/\n#' @return A table of CSR ratings collected from your input page\n#' @importFrom V8 v8\n#' @importFrom httr content use_proxy\n#' @importFrom stringi stri_replace_last_fixed stri_replace_first_fixed\n#' @importFrom jsonlite fromJSON\n#' @importFrom data.table rbindlist\n#' @examples\n#' \\dontrun{\n#' # get first two pages of CSR ratings in 2015\n#' getCSRRating(1,3)\n#' }\n#' @export\n\n\n\ngetCSRRating <- function(startPage, endPage, year = 2015, proxy = FALSE) {\n  date <- paste(year, '12', '31', sep = '-')\n  page <- startPage # set up initial value\n  times <- 0\n  if (proxy == TRUE) {\n    proxyPool <- getProxy()[,1:2]\n    message('There might by error messages when you choose to use proxy, just ignore them.\n          When it stayed for a long time, just click \"stop\", to start another round')\n  } else if (proxy == FALSE) {\n    proxyPool <- NULL\n  } else {\n    message(\"Wrong input, it's TRUE or FALSE\")\n  }\n  proxyIndex <- 1 #proxyIndex starts from1\n  startTime <- Sys.time() # Get the start time, if it exceeds 1 hour, load proxy again.\n\n  repeat {\n\n    unitList <- tryCatch({\n\n      getCSRRating_unit(page, date = date, proxy = proxyPool[proxyIndex,])\n\n    },error = function(cond) {\n      message(paste('\\n', Sys.time(), \" Proxy doestn't work or ...\\n\"))\n      message(cond)\n      return(1)\n    })\n\n    if (length(unitList) == 1) {\n      times <- 0\n      proxyIndex <- proxyIndex + 1# if proxy does't work or 30 pages are scraped, change proxy\n\n      if (proxyIndex == 301) {\n        message('\\nrefreshe proxy pool...')\n\n        if (proxy == TRUE) {\n          proxyPool <- getProxy()[,1:2]\n        } else if (proxy == FALSE) {\n          proxyPool <- NULL\n        } else {\n          message(\"Wrong input, it's TRUE or FALSE\")\n        }\n\n        proxyIndex <- 1\n      }\n\n    } else {\n\n\n      if (times == 0) {\n        totalList <- unitList\n      } else {\n        # bind the new list to the total list\n        totalList <- rbindlist(totalList, unitList)\n      }\n\n      times <- times + 1\n      page <- page + 1\n      # here one more control, when page reaches 499, change proxy\n      # But if using proxy, usually no need to worry about the ip block\n      if (times == 1000000) {\n        # Just in case, usually it will not reach that many times\n        stop(\"1000000 times, change proxy...\\n\")\n        # randomNum <- round(runif(1, 1, 300))\n      } else {\n        message(paste(\"page\", page - 1))\n      }\n    }\n    if (page > endPage) break\n    endTime <- Sys.time()\n    if (is.integer((endTime - startTime)/5400)) {\n      message(\"\\nRefresh proxy pool...\")\n      if (proxy == TRUE) {\n        proxyPool <- getProxy()[,1:2]\n      } else if (proxy == FALSE) {\n        proxyPool <- NULL\n      } else {\n        message(\"Wrong input, it's TRUE or FALSE\")\n      }\n    }\n  }\n\n  return(totalList)\n}\n",
    "created" : 1484839943333.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "479613126",
    "id" : "CCC86D4F",
    "lastKnownWriteTime" : 1487606572,
    "last_content_update" : 1487606572704,
    "path" : "~/GitHub/gfer/R/getCSRRating.R",
    "project_path" : "R/getCSRRating.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}